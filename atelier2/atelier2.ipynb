{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atelier #2 - Carvana Image Masking Challenge avec PyTorch\n",
    "### Automatically identify the boundaries of the car in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](static/header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque noteobook commence par ces trois lignes; ils garantissent que toutes les modifications apportées aux modules et paquets que vous développez \"en dehors\" du Jupyter Notebook sont automatiquement rechargées lorsque modifiés. Tous les graphiques et images sont affichées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "\n",
    "from IPython.core.display import Image, display\n",
    "from PIL import Image as Img\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from eval import eval_net\n",
    "\n",
    "from utils.dataset import BasicDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vérification de CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: red\">Pour la suite de l'exercice, la mémoire du GPU peut-être libérée en redémarrant le kernel</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Répertoires des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérez les données sur le site [Kaggle](https://www.kaggle.com/c/carvana-image-masking-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES = '<completer>'\n",
    "MASKS = '<completer>'\n",
    "CHECKPOINTS = 'checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image non segmentée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = IMAGES + '00087a6bd4dc_01.jpg'\n",
    "display(Img.open(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = MASKS + '00087a6bd4dc_01_mask.gif'\n",
    "display(Img.open(msk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hyper-paramètres d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'époques\n",
    "epochs = 1\n",
    "# Taille de la bacth\n",
    "batch_size = 4\n",
    "# Facteur d'apprentissage\n",
    "lr = 0.001\n",
    "# Facteur de redimensionnement des images (downscaling)\n",
    "scale = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pourcentage de données de validation\n",
    "validation_ratio = 0.5\n",
    "# Active la sauvegarde par checkpoints\n",
    "save_cp = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Le modèle de type U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](static/unet-pub.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](static/architecture-unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Compléter cette méthode pour obtenir l'architecture UNet présentée ci-dessus\n",
    "        # ~ 10 lignes\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(n_channels=3, n_classes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Préparation de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None #\"checkpoints/CP_epoch1.pth\" #None # Remplacer par votre modèle pré-entraîné\n",
    "\n",
    "if model is not None:\n",
    "    net.load_state_dict(torch.load(model, map_location=device))\n",
    "    print(f'Model loaded from {model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device=device)\n",
    "torch.backends.cudnn.benchmark = True  # faster convolutions, but more memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BasicDataset(IMAGES, MASKS, scale)\n",
    "n_val = int(len(dataset) * validation_ratio)\n",
    "n_train = len(dataset) - n_val\n",
    "torch.manual_seed(2019)\n",
    "train, val = random_split(dataset, [n_train, n_val] )\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification des paramètres d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Starting training:\n",
    "    Epochs:          {epochs}\n",
    "    Batch size:      {batch_size}\n",
    "    Learning rate:   {lr}\n",
    "    Training size:   {n_train}\n",
    "    Validation size: {n_val}\n",
    "    Device:          {device.type}\n",
    "    Images scaling:  {scale}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tensorboard\n",
    "writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{scale}')\n",
    "global_step = 0\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8)\n",
    "if net.n_classes > 1:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            imgs = batch['image']\n",
    "            true_masks = batch['mask']\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            masks_pred = net(imgs)\n",
    "            loss = criterion(masks_pred, true_masks)\n",
    "            epoch_loss += loss.item()\n",
    "            writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "\n",
    "            pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(imgs.shape[0])\n",
    "            global_step += 1\n",
    "            if global_step % (len(dataset) // (10 * batch_size)) == 0:\n",
    "                val_score = eval_net(net, val_loader, device, n_val)\n",
    "                if net.n_classes > 1:\n",
    "                    print('Validation cross entropy: {}'.format(val_score))\n",
    "                    writer.add_scalar('Loss/test', val_score, global_step)\n",
    "\n",
    "                else:\n",
    "                    print('Validation Dice Coeff: {}'.format(val_score))\n",
    "                    writer.add_scalar('Dice/test', val_score, global_step)\n",
    "\n",
    "                writer.add_images('images', imgs, global_step)\n",
    "                if net.n_classes == 1:\n",
    "                    writer.add_images('masks/true', true_masks, global_step)\n",
    "                    writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
    "\n",
    "    if save_cp:\n",
    "        try:\n",
    "            os.mkdir(CHECKPOINTS)\n",
    "            print('Created checkpoint directory')\n",
    "        except OSError:\n",
    "            pass\n",
    "        torch.save(net.state_dict(), CHECKPOINTS + f'CP_epoch{epoch + 1}.pth')\n",
    "        print(f'Checkpoint {epoch + 1} saved !')\n",
    "\n",
    "# Fermeture du writer pour TensorBoard\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis un terminal, démarrez Tensorboard avec la commande. **Pensez à ouvrir le port 6006 (Firewall Rules)**\n",
    "\n",
    "`tensorboard --host 0.0.0.0 --logdir=runs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Optionnel - 2018 Data Science Bowl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayez le U-Net avec les données du 2018 [Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Références"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Carvana Image Masking Challenge | Kaggle | Private leaderboard](https://www.kaggle.com/c/carvana-image-masking-challenge/leaderboard)\n",
    "* [UNet: semantic segmentation with PyTorch](https://github.com/milesial/Pytorch-UNet)\n",
    "* [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
